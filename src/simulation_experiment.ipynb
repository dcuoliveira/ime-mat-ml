{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import torch\n",
    "from torch.autograd import grad\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import torch\n",
    "from torch.autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sem_data(n, mu_x, sigma_x, sigma_y, sigma_x2, rho=0):\n",
    "    X1 = np.random.normal(mu_x, sigma_x, n)\n",
    "    # If rho is not 0, we introduce correlation between X1 and noise in Y\n",
    "    noise_y = np.random.normal(0, sigma_y * np.sqrt(1 - rho**2), n) + rho * X1\n",
    "    Y = X1 + noise_y\n",
    "    X2 = Y + np.random.normal(0, sigma_x2, n)\n",
    "    return np.column_stack((Y, X1, X2))\n",
    "\n",
    "class InvariantRiskMinimization(object):\n",
    "    def __init__(self, environments, args):\n",
    "        self.best_reg = 0\n",
    "        self.best_err = float('inf')\n",
    "\n",
    "        # Assumes the last environment is the validation set\n",
    "        x_val, y_val = environments[-1]\n",
    "\n",
    "        for reg in [0, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "            self.train(environments[:-1], args, reg=reg)\n",
    "            err = torch.mean((x_val @ self.solution() - y_val) ** 2).item()\n",
    "\n",
    "            if args[\"verbose\"]:\n",
    "                print(f\"IRM (reg={reg:.3f}) has {err:.3f} validation error.\")\n",
    "\n",
    "            if err < self.best_err:\n",
    "                self.best_err = err\n",
    "                self.best_reg = reg\n",
    "                self.best_phi = self.phi.clone()\n",
    "\n",
    "        self.phi = self.best_phi\n",
    "\n",
    "    def train(self, environments, args, reg=0):\n",
    "        dim_x = environments[0][0].shape[1]\n",
    "\n",
    "        self.phi = torch.nn.Parameter(torch.eye(dim_x, dim_x))\n",
    "        self.w = torch.ones((dim_x, 1), requires_grad=True)\n",
    "\n",
    "        opt = torch.optim.Adam([self.phi], lr=args[\"lr\"])\n",
    "        mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "        for iteration in range(args[\"n_iterations\"]):\n",
    "            penalty = 0\n",
    "            error = 0\n",
    "            for x_e, y_e in environments:\n",
    "                preds = x_e @ self.phi @ self.w\n",
    "                error_e = mse_loss(preds, y_e)\n",
    "                penalty += grad(error_e, self.w, create_graph=True)[0].pow(2).mean()\n",
    "                error += error_e.item()\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss = reg * error + (1 - reg) * penalty\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            if args[\"verbose\"] and iteration % 1000 == 0:\n",
    "                w_str = ' '.join(f'{w:.2f}' for w in self.solution().view(-1))\n",
    "                print(f\"{iteration:05d} | {reg:.5f} | {error:.5f} | {penalty:.5f} | {w_str}\")\n",
    "\n",
    "    def solution(self):\n",
    "        return self.phi @ self.w\n",
    "\n",
    "def to_tensor(data):\n",
    "    return torch.tensor(data, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset with variances as described in training environments\n",
    "n_train = 1000  # Number of samples in training\n",
    "\n",
    "train_env1 = generate_sem_data(n_train, 0, np.sqrt(10), np.sqrt(10), 1)\n",
    "train_env2 = generate_sem_data(n_train, 0, np.sqrt(20), np.sqrt(20), 1)\n",
    "train_data = np.vstack((train_env1, train_env2))\n",
    "\n",
    "train_env3 = generate_sem_data(n_train, 0, np.sqrt(10), np.sqrt(10), 1)\n",
    "\n",
    "# Test dataset with variance shift\n",
    "test_var_shift = generate_sem_data(n_train, 0, np.sqrt(50), np.sqrt(50), 1)\n",
    "test_data_var_shift = np.vstack(test_var_shift)\n",
    "\n",
    "# Test dataset with mean shift\n",
    "test_mean_shift = generate_sem_data(n_train, 15, np.sqrt(20), np.sqrt(20), 1)\n",
    "test_data_mean_shift = np.vstack(test_mean_shift)\n",
    "\n",
    "# Test dataset with correlation shift\n",
    "test_corr_shift = generate_sem_data(n_train, 0, np.sqrt(20), np.sqrt(20), 1, rho=0.7)\n",
    "test_data_corr_shift = np.vstack(test_corr_shift)\n",
    "\n",
    "# Combine into dataframes for easier handling\n",
    "columns = [ 'X1', 'X2', 'Y']\n",
    "train_df = pd.DataFrame(train_data, columns=columns)\n",
    "train_df2 = pd.DataFrame(train_env3, columns=columns)\n",
    "test_var_shift_df = pd.DataFrame(test_data_var_shift, columns=columns)\n",
    "test_mean_shift_df = pd.DataFrame(test_data_mean_shift, columns=columns)\n",
    "test_corr_shift_df = pd.DataFrame(test_data_corr_shift, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training dataset\n",
    "model.fit(train_df[['X1', 'X2']], train_df['Y'])\n",
    "\n",
    "# Create a dictionary to store the MSE and MAE for each test set\n",
    "metrics = {}\n",
    "\n",
    "# Predict and evaluate on a similar training data\n",
    "predictions_standard = model.predict(train_df2[['X1', 'X2']])\n",
    "metrics['standard'] = {\n",
    "    'MSE': mean_squared_error(train_df2['Y'], predictions_standard),\n",
    "    'MAE': mean_absolute_error(train_df2['Y'], predictions_standard)\n",
    "}\n",
    "\n",
    "# Predict and evaluate on the test dataset with variance shift\n",
    "predictions_var_shift = model.predict(test_var_shift_df[['X1', 'X2']])\n",
    "metrics['variance_shift'] = {\n",
    "    'MSE': mean_squared_error(test_var_shift_df['Y'], predictions_var_shift),\n",
    "    'MAE': mean_absolute_error(test_var_shift_df['Y'], predictions_var_shift)\n",
    "}\n",
    "\n",
    "# Predict and evaluate on the test dataset with mean shift\n",
    "predictions_mean_shift = model.predict(test_mean_shift_df[['X1', 'X2']])\n",
    "metrics['mean_shift'] = {\n",
    "    'MSE': mean_squared_error(test_mean_shift_df['Y'], predictions_mean_shift),\n",
    "    'MAE': mean_absolute_error(test_mean_shift_df['Y'], predictions_mean_shift)\n",
    "}\n",
    "\n",
    "# Predict and evaluate on the test dataset with correlation shift\n",
    "predictions_corr_shift = model.predict(test_corr_shift_df[['X1', 'X2']])\n",
    "metrics['correlation_shift'] = {\n",
    "    'MSE': mean_squared_error(test_corr_shift_df['Y'], predictions_corr_shift),\n",
    "    'MAE': mean_absolute_error(test_corr_shift_df['Y'], predictions_corr_shift)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test standard, MSE: 0.9973065257072449, MAE: 0.7931180596351624\n",
      "Test variance_shift, MSE: 0.9421562552452087, MAE: 0.776894748210907\n",
      "Test mean_shift, MSE: 1.0360878705978394, MAE: 0.8153470754623413\n",
      "Test correlation_shift, MSE: 0.9364076852798462, MAE: 0.7630943655967712\n"
     ]
    }
   ],
   "source": [
    "# Convert the datasets to PyTorch tensors\n",
    "train_tensors1 = [[train_env1[:, 0:2], train_env1[:, 2:]], [train_env2[:, 0:2], train_env2[:, 2:]]]\n",
    "train_tensors2 = [train_env3[:, 0:2], train_env3[:, 2:]]\n",
    "test_var_shift_tensors = [test_var_shift[:, 0:2], test_var_shift[:, 2:]]\n",
    "test_mean_shift_tensors = [test_mean_shift[:, 0:2], test_mean_shift[:, 2:]]\n",
    "test_corr_shift_tensors = [test_corr_shift[:, 0:2], test_corr_shift[:, 2:]]\n",
    "\n",
    "train_tensors1 = [(to_tensor(env[0]), to_tensor(env[1])) for env in train_tensors1]\n",
    "train_tensors2 = [to_tensor(tensor_obj) for tensor_obj in train_tensors2]\n",
    "test_var_shift_tensors = [to_tensor(tensor_obj) for tensor_obj in test_var_shift_tensors]\n",
    "test_mean_shift_tensors = [to_tensor(tensor_obj) for tensor_obj in test_mean_shift_tensors]\n",
    "test_corr_shift_tensors = [to_tensor(tensor_obj) for tensor_obj in test_corr_shift_tensors]\n",
    "\n",
    "\n",
    "# Define arguments for training\n",
    "args = {\n",
    "    \"lr\": 1e-3,\n",
    "    \"n_iterations\": 500000,\n",
    "    \"verbose\": False\n",
    "}\n",
    "\n",
    "# Initialize the IRM model and train on the training environments\n",
    "irm_model = InvariantRiskMinimization(train_tensors1, args)\n",
    "\n",
    "# Evaluate on the test datasets\n",
    "names = [\"standard\", 'variance_shift', 'mean_shift', 'correlation_shift']\n",
    "test_datasets = [train_tensors2, test_var_shift_tensors, test_mean_shift_tensors, test_corr_shift_tensors]\n",
    "metrics2 = {}\n",
    "for i, (x_test, y_test) in enumerate(test_datasets):\n",
    "    y_pred = x_test @ irm_model.solution()\n",
    "    mse =  mean_squared_error(y_test, y_pred.detach())\n",
    "    mae = mean_absolute_error(y_test, y_pred.detach())\n",
    "\n",
    "    print(f\"Test {names[i]}, MSE: {mse.item()}, MAE: {mae.item()}\")\n",
    "\n",
    "    metrics2[names[i]] = {\n",
    "        'MSE': mse.item(),\n",
    "        'MAE': mae.item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcuoliveira",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
